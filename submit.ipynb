{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import datetime\n",
    "import math\n",
    "import gc\n",
    "print('Loading data...')\n",
    "\n",
    "#import dataset\n",
    "data_path = '~/Desktop/DS5110/project/project/'\n",
    "train = pd.read_csv(data_path + 'train.csv', dtype={'msno' : 'category',\n",
    "                                                'source_system_tab' : 'category',\n",
    "                                                  'source_screen_name' : 'category',\n",
    "                                                  'source_type' : 'category',\n",
    "                                                  'target' : np.uint8,\n",
    "                                                  'song_id' : 'category'})\n",
    "test = pd.read_csv(data_path + 'test.csv', dtype={'msno' : 'category',\n",
    "                                                'source_system_tab' : 'category',\n",
    "                                                'source_screen_name' : 'category',\n",
    "                                                'source_type' : 'category',\n",
    "                                                'song_id' : 'category'})\n",
    "songs = pd.read_csv(data_path + 'songs.csv',dtype={'genre_ids': 'category',\n",
    "                                                  'language' : 'category',\n",
    "                                                  'artist_name' : 'category',\n",
    "                                                  'composer' : 'category',\n",
    "                                                  'lyricist' : 'category',\n",
    "                                                  'song_id' : 'category'})\n",
    "members = pd.read_csv(data_path + 'members.csv',dtype={'city' : 'category',\n",
    "                                                      'bd' : np.uint8,\n",
    "                                                      'gender' : 'category',\n",
    "                                                      'registered_via' : 'category'},\n",
    "                     parse_dates=['registration_init_time','expiration_date'])\n",
    "songs_extra = pd.read_csv(data_path + 'song_extra_info.csv')\n",
    "print('Done loading...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Data merging...')\n",
    "\n",
    "#combine datasets\n",
    "train = train.merge(songs, on='song_id', how='left')\n",
    "test = test.merge(songs, on='song_id', how='left')\n",
    "\n",
    "#split time into year month day\n",
    "members['membership_days'] = members['expiration_date'].subtract(members['registration_init_time']).dt.days.astype(int)\n",
    "\n",
    "members['registration_year'] = members['registration_init_time'].dt.year\n",
    "members['registration_month'] = members['registration_init_time'].dt.month\n",
    "members['registration_date'] = members['registration_init_time'].dt.day\n",
    "\n",
    "members['expiration_year'] = members['expiration_date'].dt.year\n",
    "members['expiration_month'] = members['expiration_date'].dt.month\n",
    "members['expiration_date'] = members['expiration_date'].dt.day\n",
    "members = members.drop(['registration_init_time'], axis=1)\n",
    "\n",
    "def isrc_to_year(isrc):\n",
    "    if type(isrc) == str:\n",
    "        if int(isrc[5:7]) > 17:\n",
    "            return 1900 + int(isrc[5:7])\n",
    "        else:\n",
    "            return 2000 + int(isrc[5:7])\n",
    "    else:\n",
    "        return np.nan\n",
    "        \n",
    "songs_extra['song_year'] = songs_extra['isrc'].apply(isrc_to_year)\n",
    "songs_extra.drop(['isrc', 'name'], axis = 1, inplace = True)\n",
    "\n",
    "train = train.merge(members, on='msno', how='left')\n",
    "test = test.merge(members, on='msno', how='left')\n",
    "\n",
    "train = train.merge(songs_extra, on = 'song_id', how = 'left')\n",
    "train.song_length.fillna(200000,inplace=True)\n",
    "train.song_length = train.song_length.astype(np.uint32)\n",
    "train.song_id = train.song_id.astype('category')\n",
    "\n",
    "\n",
    "test = test.merge(songs_extra, on = 'song_id', how = 'left')\n",
    "test.song_length.fillna(200000,inplace=True)\n",
    "test.song_length = test.song_length.astype(np.uint32)\n",
    "test.song_id = test.song_id.astype('category')\n",
    "\n",
    "# import gc\n",
    "# del members, songs; gc.collect();\n",
    "\n",
    "print('Done merging...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (\"Adding new features\")\n",
    "\n",
    "def genre_id_count(x):\n",
    "    if x == 'no_genre_id':\n",
    "        return 0\n",
    "    else:\n",
    "        return x.count('|') + 1\n",
    "#set na to 'no_genre_id'\n",
    "train['genre_ids'].fillna('no_genre_id',inplace=True)\n",
    "test['genre_ids'].fillna('no_genre_id',inplace=True)\n",
    "train['genre_ids_count'] = train['genre_ids'].apply(genre_id_count).astype(np.int8)\n",
    "test['genre_ids_count'] = test['genre_ids'].apply(genre_id_count).astype(np.int8)\n",
    "\n",
    "def lyricist_count(x):\n",
    "    if x == 'no_lyricist':\n",
    "        return 0\n",
    "    else:\n",
    "        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n",
    "    return sum(map(x.count, ['|', '/', '\\\\', ';']))\n",
    "\n",
    "train['lyricist'].fillna('no_lyricist',inplace=True)\n",
    "test['lyricist'].fillna('no_lyricist',inplace=True)\n",
    "train['lyricists_count'] = train['lyricist'].apply(lyricist_count).astype(np.int8)\n",
    "test['lyricists_count'] = test['lyricist'].apply(lyricist_count).astype(np.int8)\n",
    "\n",
    "def composer_count(x):\n",
    "    if x == 'no_composer':\n",
    "        return 0\n",
    "    else:\n",
    "        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n",
    "\n",
    "train['composer'].fillna('no_composer',inplace=True)\n",
    "test['composer'].fillna('no_composer',inplace=True)\n",
    "train['composer_count'] = train['composer'].apply(composer_count).astype(np.int8)\n",
    "test['composer_count'] = test['composer'].apply(composer_count).astype(np.int8)\n",
    "\n",
    "def is_featured(x):\n",
    "    if 'feat' in str(x) :\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "train['artist_name'].fillna('no_artist',inplace=True)\n",
    "test['artist_name'].fillna('no_artist',inplace=True)\n",
    "train['is_featured'] = train['artist_name'].apply(is_featured).astype(np.int8)\n",
    "test['is_featured'] = test['artist_name'].apply(is_featured).astype(np.int8)\n",
    "\n",
    "def artist_count(x):\n",
    "    if x == 'no_artist':\n",
    "        return 0\n",
    "    else:\n",
    "        return x.count('and') + x.count(',') + x.count('feat') + x.count('&')\n",
    "\n",
    "train['artist_count'] = train['artist_name'].apply(artist_count).astype(np.int8)\n",
    "test['artist_count'] = test['artist_name'].apply(artist_count).astype(np.int8)\n",
    "\n",
    "# if artist is same as composer\n",
    "train['artist_composer'] = (train['artist_name'] == train['composer']).astype(np.int8)\n",
    "test['artist_composer'] = (test['artist_name'] == test['composer']).astype(np.int8)\n",
    "\n",
    "\n",
    "# if artist, lyricist and composer are all three same\n",
    "train['artist_composer_lyricist'] = ((train['artist_name'] == train['composer']) & (train['artist_name'] == train['lyricist']) & (train['composer'] == train['lyricist'])).astype(np.int8)\n",
    "test['artist_composer_lyricist'] = ((test['artist_name'] == test['composer']) & (test['artist_name'] == test['lyricist']) & (test['composer'] == test['lyricist'])).astype(np.int8)\n",
    "\n",
    "# is song language 17 or 45. \n",
    "def song_lang_boolean(x):\n",
    "    if '17.0' in str(x) or '45.0' in str(x):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "train['song_lang_boolean'] = train['language'].apply(song_lang_boolean).astype(np.int8)\n",
    "test['song_lang_boolean'] = test['language'].apply(song_lang_boolean).astype(np.int8)\n",
    "\n",
    "\n",
    "_mean_song_length = np.mean(train['song_length'])\n",
    "def smaller_song(x):\n",
    "    if x < _mean_song_length:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "train['smaller_song'] = train['song_length'].apply(smaller_song).astype(np.int8)\n",
    "test['smaller_song'] = test['song_length'].apply(smaller_song).astype(np.int8)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"then adding magic play_ratio\")\n",
    "lentrain=len(train['song_id']);lentest=len(test['song_id'])\n",
    "\n",
    "#create a dictionary\n",
    "_dict_ratio_composer_played_train = {k: v for k, \n",
    "                v in ( train['composer'].value_counts()/len(train['composer']) ).iteritems() }\n",
    "_dict_ratio_composer_played_test = {k: v for k, \n",
    "                v in ( test['composer'].value_counts()/len(test['composer']) ).iteritems() }\n",
    "def ratio_composer_played_train(x): \n",
    "     if x==\"no_composer\" or x==\"佚名\":\n",
    "        return 0.5/(lentrain)+0.5/lentest\n",
    "     else:  \n",
    "      try:\n",
    "        return 0.5*_dict_ratio_composer_played_train[x]+0.5*_dict_ratio_composer_played_test[x]\n",
    "      except KeyError:\n",
    "        return _dict_ratio_composer_played_train[x]\n",
    "\n",
    "def ratio_composer_played_test(x):\n",
    "    if x==\"no_composer\" or x==\"佚名\":\n",
    "         return 0.5/(lentrain)+0.5/lentest\n",
    "    else:\n",
    "      try:\n",
    "        return 0.5*_dict_ratio_composer_played_train[x]+0.5*_dict_ratio_composer_played_test[x]\n",
    "      except KeyError:\n",
    "        return _dict_ratio_composer_played_test[x]\n",
    "\n",
    "train['ratio_composer_played'] = train['composer'].apply(ratio_composer_played_train).astype(np.float64)\n",
    "test['ratio_composer_played'] = test['composer'].apply(ratio_composer_played_test).astype(np.float64)\n",
    "#######\n",
    "_dict_ratio_artist_played_train = {k: v for k, \n",
    "                v in ( train['artist_name'].value_counts()/len(train['artist_name']) ).iteritems() }\n",
    "_dict_ratio_artist_played_test = {k: v for k, \n",
    "                v in ( test['artist_name'].value_counts()/len(test['artist_name']) ).iteritems() }\n",
    "def ratio_artist_played_train(x):\n",
    "     if x==\"no_artist\" or x==\"Various Artists\" or x==\"群星\" or x==\"佚名\":\n",
    "         return 0.5/(lentrain)+0.5/lentest\n",
    "     else:\n",
    "      try:\n",
    "        return 0.5*_dict_ratio_artist_played_train[x]+0.5*_dict_ratio_artist_played_test[x]\n",
    "      except KeyError:\n",
    "        return _dict_ratio_artist_played_train[x]\n",
    "\n",
    "def ratio_artist_played_test(x):\n",
    "     if x==\"no_artist\" or x==\"Various Artists\" or x==\"群星\" or x==\"佚名\":\n",
    "         return 0.5/(lentrain)+0.5/lentest\n",
    "     else:\n",
    "      try:\n",
    "        return 0.5*_dict_ratio_artist_played_train[x]+0.5*_dict_ratio_artist_played_test[x]\n",
    "      except KeyError:\n",
    "        return _dict_ratio_artist_played_test[x]\n",
    "\n",
    "train['ratio_artist_played'] = train['artist_name'].apply(ratio_artist_played_train).astype(np.float64)\n",
    "test['ratio_artist_played'] = test['artist_name'].apply(ratio_artist_played_test).astype(np.float64)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "_dict_ratio_song_played_train = {k: v for k, \n",
    "                v in ( train['song_id'].value_counts()/len(train['song_id']) ).iteritems() }\n",
    "_dict_ratio_song_played_test = {k: v for k, \n",
    "                v in ( test['song_id'].value_counts()/len(test['song_id']) ).iteritems() }\n",
    "def ratio_song_played_train(x):\n",
    "  if x==np.nan:\n",
    "      return 0.5/(lentrain)+0.5/lentest\n",
    "  else:\n",
    "    try:\n",
    "      return 0.5*_dict_ratio_song_played_train[x]+\\\n",
    "             0.5*_dict_ratio_song_played_test[x]\n",
    "    except KeyError:\n",
    "      return _dict_ratio_song_played_train[x]\n",
    "\n",
    "def ratio_song_played_test(x):\n",
    "  if x==np.nan:\n",
    "      return 0.5/(lentrain)+0.5/lentest\n",
    "  else:\n",
    "    try:\n",
    "      return 0.5*_dict_ratio_song_played_train[x]\\\n",
    "             +0.5*_dict_ratio_song_played_test[x]\n",
    "    except KeyError:\n",
    "      return _dict_ratio_song_played_test[x]\n",
    "\n",
    "train['ratio_song_played'] = train['song_id'].apply(ratio_song_played_train).astype(np.float64)\n",
    "test['ratio_song_played'] = test['song_id'].apply(ratio_song_played_test).astype(np.float64)\n",
    "\n",
    "\n",
    "# In[186]:\n",
    "\n",
    "#songs['artist_name'].value_counts()/len(train['artist_name'])\n",
    "\n",
    "\n",
    "print(\" adding genre&lyricist ratio\")\n",
    "_dict_ratio_genre_played_train = {k: v for k, \n",
    "                v in ( train['genre_ids'].value_counts()/len(train['genre_ids']) ).iteritems() }\n",
    "_dict_ratio_genre_played_test = {k: v for k, \n",
    "                v in ( test['genre_ids'].value_counts()/len(test['genre_ids']) ).iteritems() }\n",
    "def ratio_genre_played_train(x):\n",
    "    if x==\"no_genre_id\":\n",
    "      return 0.5/(lentrain)+0.5/lentest\n",
    "    else:\n",
    "     try:\n",
    "       return 0.5*_dict_ratio_genre_played_train[x]+0.5*_dict_ratio_genre_played_test[x]\n",
    "     except KeyError:\n",
    "       return _dict_ratio_genre_played_train[x]\n",
    "\n",
    "def ratio_genre_played_test(x):\n",
    "    if x==\"no_genre_id\":\n",
    "      return 0.5/(lentrain)+0.5/lentest\n",
    "    else:\n",
    "      try:\n",
    "        return 0.5*_dict_ratio_genre_played_train[x]+0.5*_dict_ratio_genre_played_test[x]\n",
    "      except KeyError:\n",
    "        return _dict_ratio_genre_played_test[x]\n",
    "\n",
    "train['ratio_genre_played'] = train['genre_ids'].apply(ratio_genre_played_train).astype(np.float64)\n",
    "test['ratio_genre_played'] = test['genre_ids'].apply(ratio_genre_played_test).astype(np.float64)\n",
    "\n",
    "############\n",
    "_dict_ratio_lyricist_played_train = {k: v for k, \n",
    "                v in ( train['lyricist'].value_counts()/len(train['lyricist']) ).iteritems() }\n",
    "_dict_ratio_lyricist_played_test = {k: v for k, \n",
    "                v in ( test['lyricist'].value_counts()/len(test['lyricist']) ).iteritems() }\n",
    "def ratio_lyricist_played_train(x):\n",
    "     if x==\"no_lyricist\" or x==\"佚名\":\n",
    "         return 0.5/(lentrain)+0.5/lentest\n",
    "     else:\n",
    "        try:\n",
    "          return 0.5*_dict_ratio_lyricist_played_train[x]+0.5*_dict_ratio_lyricist_played_test[x]\n",
    "        except KeyError:\n",
    "          return _dict_ratio_lyricist_played_train[x]\n",
    "\n",
    "def ratio_lyricist_played_test(x):\n",
    "    if x==\"no_lyricist\" or x==\"佚名\":\n",
    "         return 0.5/(lentrain)+0.5/lentest\n",
    "    else:\n",
    "      try:\n",
    "        return 0.5*_dict_ratio_lyricist_played_train[x]+0.5*_dict_ratio_lyricist_played_test[x]\n",
    "      except KeyError:\n",
    "        return _dict_ratio_lyricist_played_test[x]\n",
    "\n",
    "train['ratio_lyricist_played'] = train['lyricist'].apply(ratio_lyricist_played_train).astype(np.float64)\n",
    "test['ratio_lyricist_played'] = test['lyricist'].apply(ratio_lyricist_played_test).astype(np.float64)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create new feature: for each user, calculate the ratio of certain artist was played in total play\n",
    "a=pd.concat([train.drop(['target'],axis=1),test.drop(['id'],axis=1)]).groupby(\"msno\",as_index=False).agg({\"artist_name\":{\"uni_art\":pd.Series.nunique, #a is for user's play info\n",
    "                                                                           \"user_play\":\"count\"}})\n",
    "a.columns=a.columns.droplevel(level=0)\n",
    "a=a.rename(columns={\"\":\"msno\"})\n",
    "train=train.merge(a, on=\"msno\", how=\"left\")\n",
    "test=test.merge(a, on=\"msno\", how=\"left\")\n",
    "train[\"artist_habit\"]=train[\"uni_art\"]/train[\"user_play\"]\n",
    "test[\"artist_habit\"]=test[\"uni_art\"]/test[\"user_play\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_aritst_count=pd.concat([train.drop(['target'],axis=1),test.drop(['id'],axis=1)]).groupby([\"msno\",\n",
    "        \"artist_name\"],as_index=False).agg({\"song_id\":{\"user_artist_count\":\"count\"}})\n",
    "user_aritst_count.columns=user_aritst_count.columns.droplevel(level=0)\n",
    "user_aritst_count.columns.values[0]=\"msno\"   \n",
    "user_aritst_count.columns.values[1]=\"artist_name\"\n",
    "train=train.merge(user_aritst_count, on=[\"msno\",\"artist_name\"], how=\"left\")\n",
    "test=test.merge(user_aritst_count, on=[\"msno\", \"artist_name\"],how=\"left\")\n",
    "train[\"coolartist_like\"]=train[\"user_artist_count\"]/train[\"user_play\"]\n",
    "test[\"coolartist_like\"]=test[\"user_artist_count\"]/test[\"user_play\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_language_count=pd.concat([train.drop(['target'],axis=1),\n",
    "                    test.drop(['id'],axis=1)]).groupby([\"msno\",\n",
    "                \"language\"],as_index=False).agg({\"song_id\":{\"cooluser_language_count\":\"count\"}})\n",
    "user_language_count.columns=user_language_count.columns.droplevel(level=0)\n",
    "user_language_count.columns.values[0]=\"msno\"\n",
    "user_language_count.columns.values[1]=\"language\"\n",
    "train=train.merge(user_language_count, on=[\"msno\",\"language\"], how=\"left\")\n",
    "test=test.merge(user_language_count, on=[\"msno\", \"language\"],how=\"left\")\n",
    "train[\"coollangu_like\"]=train[\"cooluser_language_count\"]/train[\"user_play\"]\n",
    "test[\"coollangu_like\"]=test[\"cooluser_language_count\"]/test[\"user_play\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_genre=pd.concat([train.drop(['target'],axis=1),\n",
    "                    test.drop(['id'],axis=1)]).groupby(\"msno\",\n",
    "            as_index=False).agg({\"genre_ids\":{\"cooluni_genre\":pd.Series.nunique}})\n",
    "unique_genre.columns=unique_genre.columns.droplevel(level=0)\n",
    "unique_genre=unique_genre.rename(columns={\"\":\"msno\"})\n",
    "train=train.merge(unique_genre, on=\"msno\", how=\"left\")\n",
    "test=test.merge(unique_genre, on=\"msno\", how=\"left\")\n",
    "train[\"coolgenre_habit\"]=train[\"cooluni_genre\"]/train[\"user_play\"]\n",
    "test[\"coolgenre_habit\"]=test[\"cooluni_genre\"]/test[\"user_play\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_genre_count=pd.concat([train.drop(['target'],axis=1),\n",
    "                    test.drop(['id'],axis=1)]).groupby([\"msno\",\n",
    "\"genre_ids\"],as_index=False).agg({\"song_id\":{\"cooluser_genre_count\":\"count\"}})\n",
    "user_genre_count.columns=user_genre_count.columns.droplevel(level=0)\n",
    "user_genre_count.columns.values[0]=\"msno\"\n",
    "user_genre_count.columns.values[1]=\"genre_ids\"\n",
    "train=train.merge(user_genre_count, on=[\"msno\",\"genre_ids\"], how=\"left\")\n",
    "test=test.merge(user_genre_count, on=[\"msno\", \"genre_ids\"],how=\"left\")\n",
    "train[\"coolgenre_like\"]=train[\"cooluser_genre_count\"]/train[\"user_play\"]\n",
    "test[\"coolgenre_like\"]=test[\"cooluser_genre_count\"]/test[\"user_play\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_lyri_count=pd.concat([train.drop(['target'],axis=1),\n",
    "                    test.drop(['id'],axis=1)]).groupby([\"msno\",\n",
    "\"lyricist\"],as_index=False).agg({\"song_id\":{\"cooluser_lyri_count\":\"count\"}})\n",
    "user_lyri_count.columns=user_lyri_count.columns.droplevel(level=0)\n",
    "user_lyri_count.columns.values[0]=\"msno\"\n",
    "user_lyri_count.columns.values[1]=\"lyricist\"\n",
    "train=train.merge(user_lyri_count, on=[\"msno\",\"lyricist\"], how=\"left\")\n",
    "test=test.merge(user_lyri_count, on=[\"msno\", \"lyricist\"],how=\"left\")\n",
    "train[\"coollyri_like\"]=train[\"cooluser_lyri_count\"]/train[\"user_play\"]\n",
    "test[\"coollyri_like\"]=test[\"cooluser_lyri_count\"]/test[\"user_play\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_compo_count=pd.concat([train.drop(['target'],axis=1),\n",
    "                    test.drop(['id'],axis=1)]).groupby([\"msno\",\n",
    "\"composer\"],as_index=False).agg({\"song_id\":{\"cooluser_compo_count\":\"count\"}})\n",
    "user_compo_count.columns=user_compo_count.columns.droplevel(level=0)\n",
    "user_compo_count.columns.values[0]=\"msno\"\n",
    "user_compo_count.columns.values[1]=\"composer\"\n",
    "train=train.merge(user_compo_count, on=[\"msno\",\"composer\"], how=\"left\")\n",
    "test=test.merge(user_compo_count, on=[\"msno\", \"composer\"],how=\"left\")\n",
    "train[\"coolcompo_like\"]=train[\"cooluser_compo_count\"]/train[\"user_play\"]\n",
    "test[\"coolcompo_like\"]=test[\"cooluser_compo_count\"]/test[\"user_play\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_leng_count=pd.concat([train.drop(['target'],axis=1),\n",
    "                    test.drop(['id'],axis=1)]).groupby([\"msno\"],\n",
    "    as_index=False).agg({\"song_length\":{\"cooluser_length_mean\":\"mean\"}})\n",
    "user_leng_count.columns=user_leng_count.columns.droplevel(level=0)\n",
    "user_leng_count.columns.values[0]=\"msno\"\n",
    "train=train.merge(user_leng_count, on=\"msno\", how=\"left\")\n",
    "test=test.merge(user_leng_count, on=\"msno\",how=\"left\")\n",
    "train[\"coolleng_like\"]=train[\"song_length\"]/train[\"cooluser_length_mean\"]\n",
    "test[\"coolleng_like\"]=test[\"song_length\"]/test[\"cooluser_length_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_year_count=pd.concat([train.drop(['target'],axis=1),\n",
    "                    test.drop(['id'],axis=1)]).groupby([\"msno\"],\n",
    "    as_index=False).agg({\"song_year\":{\"cooluser_year_mean\":pd.Series.mean}})\n",
    "user_year_count.columns=user_year_count.columns.droplevel(level=0)\n",
    "user_year_count.columns.values[0]=\"msno\"\n",
    "train=train.merge(user_year_count, on=\"msno\", how=\"left\")\n",
    "test=test.merge(user_year_count, on=\"msno\",how=\"left\")\n",
    "train[\"coolyear_like\"]=train[\"song_year\"]-train[\"cooluser_year_mean\"]\n",
    "test[\"coolyear_like\"]=test[\"song_year\"]-test[\"cooluser_year_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert(x):\n",
    "    if x==0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return x\n",
    "train[\"bd2\"]=train[\"bd\"].apply(convert).astype(np.float64)\n",
    "test[\"bd2\"]=test[\"bd\"].apply(convert).astype(np.float64)\n",
    "song_bd_mean=pd.concat([train.drop(['target'],axis=1),\n",
    "                    test.drop(['id'],axis=1)]).groupby([\"song_id\"],\n",
    "    as_index=False).agg({\"bd2\":{\"coolsong_bd_mean\":pd.Series.mean},\n",
    "                         \"msno\":{\"coolsong_play\":\"count\"}})\n",
    "song_bd_mean.columns=song_bd_mean.columns.droplevel(level=0)\n",
    "song_bd_mean.columns.values[0]=\"song_id\"\n",
    "train=train.merge(song_bd_mean, on=\"song_id\", how=\"left\")\n",
    "test=test.merge(song_bd_mean, on=\"song_id\",how=\"left\")\n",
    "train[\"coolbd_like\"]=train[\"bd2\"]-train[\"coolsong_bd_mean\"]\n",
    "test[\"coolbd_like\"]=test[\"bd2\"]-test[\"coolsong_bd_mean\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_gender_count=pd.concat([train.drop(['target'],axis=1),\n",
    "                    test.drop(['id'],axis=1)]).groupby([\"song_id\",\n",
    "\"gender\"],as_index=False).agg({\"msno\":{\"coolsong_gender_count\":\"count\"}})\n",
    "song_gender_count.columns=song_gender_count.columns.droplevel(level=0)\n",
    "song_gender_count.columns.values[0]=\"song_id\"\n",
    "song_gender_count.columns.values[1]=\"gender\"\n",
    "train=train.merge(song_gender_count, on=[\"song_id\",\"gender\"], how=\"left\")\n",
    "test=test.merge(song_gender_count, on=[\"song_id\", \"gender\"],how=\"left\")\n",
    "train[\"coolgender_like\"]=train[\"coolsong_gender_count\"]/train[\"coolsong_play\"]\n",
    "test[\"coolgender_like\"]=test[\"coolsong_gender_count\"]/test[\"coolsong_play\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combine external datasets\n",
    "user_info=pd.read_csv('~/Desktop/user_logs_final.csv')\n",
    "train = train.merge(user_info, on='msno', how='left')\n",
    "test = test.merge(user_info, on='msno', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (\"Train test and validation sets\")\n",
    "for col in train.columns:\n",
    "    if train[col].dtype == object:\n",
    "        train[col] = train[col].astype('category')\n",
    "        test[col] = test[col].astype('category')\n",
    "\n",
    "\n",
    "X_train = train.drop([#'num_25','num_50','num_985',\n",
    "                      #'num_100',\n",
    "                      #'days_listened',\n",
    "    #'target','ratio_artist_played','ratio_composer_played', \n",
    "    #'ratio_lyricist_played', 'ratio_genre_played'], \n",
    "    'target','bd'], axis=1)\n",
    "y_train = train['target'].values\n",
    "\n",
    "\n",
    "X_test = test.drop([#'num_25','num_50','num_985',\n",
    "                    #  'num_100', 'id'\n",
    "                    #  'days_listened',\n",
    "   # 'ratio_artist_played','ratio_composer_played', \n",
    "   # 'ratio_lyricist_played', 'ratio_genre_played'\n",
    "                    'id','bd'], axis=1)\n",
    "ids = test['id'].values\n",
    "\n",
    "\n",
    "# del train, test; gc.collect();\n",
    "\n",
    "d_train_final = lgb.Dataset(X_train, y_train)\n",
    "watchlist_final = lgb.Dataset(X_train, y_train)\n",
    "print('Processed data...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting': 'dart',\n",
    "        'learning_rate': 0.1,\n",
    "        'verbose': 0,\n",
    "        'num_leaves': 250,\n",
    "#        'bagging_fraction': 0.95,\n",
    "#        'bagging_freq': 1,\n",
    "#        'bagging_seed': 1,\n",
    "#        'feature_fraction': 0.9,\n",
    "#        'feature_fraction_seed': 1,\n",
    "        'max_bin': 256,\n",
    "#       'max_depth': 10,\n",
    "        'num_rounds': 360,\n",
    "        'metric' : 'auc'\n",
    "    }\n",
    "\n",
    "model_f2 = lgb.train(params, train_set=d_train_final,  valid_sets=watchlist_final, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_test_2 = model_f2.predict(X_test)\n",
    "subm = pd.DataFrame()\n",
    "subm['id'] = ids\n",
    "subm['target'] = p_test_2\n",
    "subm.to_csv(data_path + 'submission_lgbm_dart14.csv.gz', compression = 'gzip', index=False, float_format = '%.5f')\n",
    "\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
